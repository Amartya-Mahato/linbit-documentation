<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="ch-latency" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Optimizing DRBD latency</title>
  <section id="s-latency-hardware">
    <title>Hardware considerations</title>
    <itemizedlist>
      <listitem>
	<formalpara>
	  <title>I/O subsystem latency</title>
	  <para>I/O subsystem latency is primarily a function of disk
	    rotation speed. Thus, using fast-spinning disks is a valid
	    approach for reducing I/O subsystem latency.</para>
	</formalpara>
	<para>Likewise, the use of a battery-backed write cache
	  (<acronym>BBWC</acronym>) reduces write completion times,
	  also reducing write latency. Most reasonable storage
	  subsystems come with some form of battery-backed cache, and
	  allow the administrator to configure which portion of this
	  cache is used for read and write operations. The recommended
	  approach is to disable the disk read cache completely and
	  use all cache memory available for the disk write
	  cache.</para>
      </listitem>
      <listitem>
	<formalpara>
	  <title>Network latency</title>
	  <para>Network latency is, in essence, the packet round-trip
	    time (<acronym>RTT</acronym>) between hosts. It is
	    influenced by a number of factors, most of which are
	    irrelevant on the dedicated, back-to-back network
	    connections recommended for use as DRBD replication links.
	    Thus, it is sufficient to accept that a certain amount of
	    latency always exists in Gigabit Ethernet links, which
	    typically is on the order of 100 to 200 microseconds
	    (&mu;s) packet RTT.</para>
	</formalpara>
	<para>Network latency may typically be pushed below this limit
	  only by using lower-latency network protocols, such as
	  well-configured IP over InfiniBand or over Scalable Coherent
	  Interface (<acronym>SCI</acronym>).</para>
      </listitem>
    </itemizedlist>
  </section>
  <section id="s-latency-overhead-expectations">
    <title>Latency overhead expectations</title>
    <para>As for throughput, when estimating the latency overhead
      associated with DRBD, there are some important natural
      limitations to consider:
	<itemizedlist>
	<listitem>
	  <para>DRBD latency is bound by that of the raw I/O
	    subsystem.</para>
	</listitem>
	<listitem>
	  <para>DRBD latency is bound by the available network
	    latency.</para>
	</listitem>
	</itemizedlist>
    </para>
    <para>The <emphasis>sum</emphasis> of the two establishes the
      theoretical latency <emphasis>minimum</emphasis> incurred to
      DRBD. DRBD then adds to that latency a slight additional latency
      overhead, which can be expected to be less than 1
      percent.</para>
    <itemizedlist>
      <listitem>
	<para>Consider the example of a local disk subsystem with a
	  write latency of 3ms and a network link with one of 0.2ms.
	  Then the expected DRBD latency would be 3.2 ms or a roughly
	  7-percent latency increase over just writing to a local
	  disk.
	</para>
      </listitem>
    </itemizedlist>
    <note>
      <para>Latency may be influenced by a number of other factors,
	including CPU cache misses, context switches, and
	others.</para>
    </note>
  </section>
  <section id="s-latency-tuning">
    <title>DRBD tuning recommendations</title>
    <xi:include href="todo.xml"/>
  </section>
</chapter>
