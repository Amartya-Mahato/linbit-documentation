<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="ch-fundamentals">
  <title>DRBD Fundamentals</title>
  <para>The Distributed Replicated Block Device (DRBD) is a
    software-based, shared-nothing, replicated storage solution
    mirroring the content of block devices (hard disks, partitions,
    logical volumes etc.) between servers.</para>
  <para>DRBD mirrors data
      <itemizedlist>
      <listitem>
	<formalpara>
	  <title>In real time</title>
	  <para>Replication occurs continuously, while applications
	    modify the data on the device.</para>
	</formalpara>
      </listitem>
      <listitem>
	<formalpara>
	  <title>Transparently</title>
	  <para>The applications that store their data on the mirrored
	    device are oblivious of the fact that the data is in fact
	    stored on several computers.</para>
	</formalpara>
      </listitem>
      <listitem>
	<formalpara>
	  <title>Synchronously or asynchronously</title>
	  <para>With synchronous mirroring, a writing application is
	    notified of write completion only after the write has been
	    carried out on both computer systems. Asynchronous
	    mirroring means the writing application is notified of
	    write completion when the write has completed locally, but
	    before the write has propagated to the peer system.</para>
	</formalpara>
      </listitem>
    </itemizedlist>
  </para>
  <section id="s-kernel-module">
    <title>Kernel module</title>
    <para><indexterm>
	<primary>kernel module</primary>
      </indexterm>DRBD's core functionality is implemented by way of
      a Linux kernel module. Specifically, DRBD constitutes a driver
      for a virtual block device, so DRBD is situated <quote>right
	near the bottom</quote> of a system's I/O stack. Because of
      this, DRBD is extremely flexible and versatile, which makes it a
      replication solution suitable for adding high availability to
      just about any application.</para>
    <important>
      <para>DRBD is, by definition and as mandated by the Linux kernel
	architecture, agnostic of the layers above it. Thus, it is
	impossible for DRBD to miraculously add features to upper
	layers that these do not possess. For example, DRBD cannot
	auto-detect file system corruption or add active-active
	clustering capability to file systems like ext3 or XFS.</para>
    </important>
    <figure id="f-drbd-linux-io-stack">
      <title>DRBD's position within the Linux I/O stack</title>
      <graphic fileref="drbd-in-kernel"/>
    </figure>
  </section>
  <section id="s-userland">
    <title>User space administration tools</title>
    <para>DRBD comes with a handful of administration tools capable of
      communicating with the kernel module, in order to be able to
      configure and administer DRBD resources.</para>
    <itemizedlist>
      <listitem>
	<formalpara>
	  <title>drbdadm</title>
	  <indexterm>
	    <primary>drbdadm</primary>
	  </indexterm>
	  <para>The high-level administration tool of the DRBD program
	    suite. It obtains all DRBD configuration parameters from
	    the configuration file
	    <filename>/etc/drbd.conf</filename>.
	    <command>drbdadm</command> acts as a front-end application
	    for both <command>drbdsetup</command> and
	    <command>drbdmeta</command> and hands off instructions to
	    either of the two for actual command execution.
	    <command>drbdadm</command> has a
	    <emphasis>dry-run</emphasis> mode, invoked with the
	    <option>-d</option> option, which exposes the commands
	    issued by the back-end programs.</para>
	</formalpara>
      </listitem>
      <listitem>
	<formalpara>
	  <title>drbdsetup</title>
	  <indexterm>
	    <primary>drbdsetup</primary>
	  </indexterm>
	  <para>The program that allows users to configure the DRBD
	    module that has been loaded into the running kernel. It is
	    the low-level tool within the DRBD program suite. When
	    using this program, all configuration parameters have to
	    be directly handed over on the command line. This allows
	    for maximum flexibility, albeit at the price of reduced
	    ease of use. Most users will use
	    <command>drbdsetup</command> very rarely.</para>
	</formalpara>
      </listitem>
      <listitem>
	<formalpara>
	  <title>drbdmeta</title>
	  <indexterm>
	    <primary>drbdmeta</primary>
	  </indexterm>
	  <para>The program which allows users to create, dump,
	    restore, and modify DRBD's meta data structures. This,
	    too, is a command that most users will use only very
	    rarely.</para>
	</formalpara>
      </listitem>
    </itemizedlist>
  </section>
  <section id="s-resources">
    <title>Resources</title>
    <para><indexterm>
	<primary>resource</primary>
	<secondary>concept</secondary>
    </indexterm>In DRBD, <emphasis>resource</emphasis> is the collective
      term that refers to all aspects of a particular replicated
      storage device. These include:
      <itemizedlist>
	<listitem>
	  <formalpara>
	    <title>Resource name</title>
	    <indexterm>
	      <primary>resource</primary>
	      <secondary>name</secondary>
	    </indexterm>
	    <para>This can be any arbitrary, US-ASCII name not
	      containing whitespace by which the resource is referred
	      to.</para>
	  </formalpara>
	</listitem>
	<listitem>
	  <formalpara>
	    <title>DRBD device</title>
	    <para>This is the virtual block device managed by DRBD. It
	      has a device major number<indexterm>
		<primary>device major number</primary>
	      </indexterm>
	      <indexterm>
		<primary>major number</primary>
		<see>device major number</see>
	      </indexterm> of 147, and its minor numbers are numbered from 0
	      onwards, as is customary. The associated block device is
	      always named
	      <filename>/dev/drbd<replaceable>m</replaceable></filename>,
	      where <replaceable>m</replaceable> is the device minor
	      number.
	      <note>
		<para>Very early DRBD versions <quote>hijacked</quote>
		  NBD's device major number 43. This is long obsolete;
		  147 is the <ulink
		    url="http://www.lanana.org/docs/device-list/">LANANA-registered</ulink>
		  DRBD device major.</para>
	      </note>
	    </para>
	  </formalpara>
	</listitem>
	<listitem>
	  <formalpara>
	    <title>Disk configuration</title>
	    <para>This entails the local copy of the data, and meta
	      data for DRBD's internal use.</para>
	  </formalpara>
	</listitem>
	<listitem>
	  <formalpara>
	    <title>Network configuration</title>
	    <para>This entails all aspects of DRBD's communication
	      with the peer node.</para>
	  </formalpara>
	</listitem>
      </itemizedlist>
    </para>
  </section>
  <section id="s-resource-roles">
    <title>Resource roles</title>
    <para><indexterm id="it-resource-role">
	<primary>resource</primary>
	<secondary>role</secondary>
    </indexterm>
    <indexterm>
	<primary>role (resources)</primary>
	<see>resource role</see>
    </indexterm>In DRBD, every <link
	linkend="s-resources">resource</link> has a
      <emphasis>role</emphasis>, which may be
      <emphasis>Primary</emphasis><indexterm>
	<primary>primary (resource role)</primary>
      </indexterm> or <emphasis>Secondary</emphasis><indexterm>
	<primary>secondary (resource role)</primary>
      </indexterm>.
      <note>
	<para>The choice of terms here is not arbitrary. These roles
	  were deliberately not named "Active" and "Passive" by DRBD's
	  creators. Primary vs. secondary refers to a concept related
	  to availability of <emphasis>storage</emphasis>, whereas
	  active vs. passive refers to the availability of an
	  <emphasis>application</emphasis>. It is usually the case in
	  a high-availability environment that the primary node is
	  also the active one, but this is by no means
	  necessary.</para>
      </note>
      <itemizedlist>
	<listitem>
	  <para>A DRBD device in the primary role can be used
	    unrestrictedly for read and write operations. It may be
	    used for creating and mounting file systems, raw or direct
	    I/O to the block device, etc.</para>
	</listitem>
	<listitem>
	  <para>A DRBD device in the secondary role receives all
	    updates from the peer node's device, but otherwise
	    disallows access completely. It can not be used by
	    applications, neither for read nor write access. The
	    reason for disallowing even read-only access to the device
	    is the necessity to maintain cache coherency, which would
	    be impossible if a secondary resource were made accessible
	    in any way.
	  </para>
	</listitem>
      </itemizedlist>
    </para>
    <para>The resource's role can, of course, be changed, either by
      <link linkend="s-switch-resource-roles">manual
	intervention</link> or by way of some automated algorithm by a
      cluster management application. Changing the resource role from
      secondary to primary is referred to as
      <emphasis>promotion,</emphasis><indexterm>
	<primary>resource</primary>
	<secondary>promotion</secondary>
      </indexterm>
      <indexterm>
	<primary>promotion (resources)</primary>
	<see>resource promotion</see>
      </indexterm> whereas the reverse operation is termed
      <emphasis>demotion.</emphasis><indexterm>
	<primary>resource</primary>
	<secondary>demotion</secondary>
      </indexterm><indexterm>
	<primary>demotion (resources)</primary>
	<see>resource demotion</see>
      </indexterm></para>
  </section>
</chapter>
