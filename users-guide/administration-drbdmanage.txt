[[ch-admin-drbdmanage]]
== Common administrative tasks - drbdmanage

Drbdmanage is an abstraction layer which takes over management of logical
volumes (LVM) and management of configuration files for DRBD. Features of
drbdmanage include creating, resizing, and removing of replicated volumes.
Additionally, drbdmanage handles taking snapshots and creating volumes in
consistency groups.

This chapter outlines typical administrative tasks encountered during
day-to-day operations. It does not cover troubleshooting tasks, these
are covered in detail in <<ch-troubleshooting>>.


[[s-dm-init-cluster]]
=== Initializing your cluster
We assume that the following steps are accomplished on *all* cluster nodes:

. The DRBD9 kernel module is installed and loaded
. +drbd-utils+ are installed
. +LVM+ tools are installed
. +drbdmanage+ and its dependencies are installed

The first step is to review the configuration file of +drbdmanage+
(+/etc/drbdmanaged.cfg+) and to create an +LVM+ volume group with the name
specified in the configuration. In the following we use the default name,
which is +drbdpool+, and assume that the volume group consists of +/dev/sda6+
and +/dev/sda7+ Creating the volume group is a step that has to be executed on
*every* cluster node:

----------------------------
vgcreate drbdpool /dev/sda6 /dev/sda7
----------------------------

The second step is to initialize the so called control volume, which is then
used to distribute your cluster configuration among all cluster nodes. If the
node has multiple interfaces, you have to specify the IP address of the
network interface that DRBD should use to communicate with other nodes in the
cluster. It is sufficient to execute this step on only one cluster node.

----------------------------
drbdmanage init 10.43.70.2
----------------------------

We recommend using 'drbdpool' as the name of your LVM volume group as it is
the default value and makes your administration life easier. If, for whatever
reasion, you decide to use a different name, make sure that the option
*drbdctrl-vg* is set accordingly in +/etc/drbdmanaged.cfg+.

[[s-dm-add-node]]
=== Adding nodes to your cluster
Adding nodes to your cluster is easy and requires a single command with two parameters:
. A node name which *must* match the output of `uname -n`
. The IP address of the node. Hint: If DNS is configured properly, the
tab-completion of +drbdmanage+ is able to complete the IP of the given node
name.

----------------------------
drbdmanage add-node bravo 10.43.70.3
----------------------------

Here we assume that the command was executed on node 'alpha'. If the 'root'
user is allowed to execute commands as 'root' on 'bravo' via +ssh+, then the
node 'bravo' will automatically join your cluster.

If +ssh+ access with public-key authentication is not possible, +drbdmanage+
will print a join command that has to be executed on node 'bravo'. You can
always query +drbdmanage+ to output the join command for a specific node:

----------------------------
drbdmanage howto-join bravo
drbdmanage join -p 6999 10.43.70.3 1 alpha 10.43.70.2 0 cOQutgNMrinBXb09A3io
----------------------------

[[s-dm-set-config]]
=== Cluster configuration
Drbdmange knows many configuration settings like the log-level or the storage
plugin that should be used (i.g., LVM, ThinLV, or ThinPool). Executing
+drbdmanage modify-config+ starts an editor that is used to specify theses
settings. The configuration is split in several sections. If an option is
specified in the +[GLOBAL]+ section, this setting is used in the entire
cluster. Additionally, it is possible to specify settings per node and per
site. Node sections follow a syntax of +[Node:nodename]+. If an option is set
globally and per node, the node setting overrules the global setting.

It is also possible to group nodes into *sites*. In order to make node 'alpha'
part of site 'mysite', you have to specify the 'site' option in alpha's node
section:

----------------------------
$ drbdmanage modify-config
[Node:alpha]
site = mysite
----------------------------

It is then also possible to specify drbdmanage settings per site using
+[Site:]+ sections. Lets assume that you want to set the 'loglevel' option in
general to 'INFO', for site 'mysite' to 'WARN' and for node alpha, which is also
part of site 'mysite' to DEBUG. This would result in the following
configuration:

----------------------------
$ drbdmanage modify-config
[GLOBAL]
loglevel = INFO

[Site:mysite]
loglevel = WARN

[Node:alpha]
site = mysite
loglevel = DEBUG
----------------------------

By executing +drbdmanage modify-config+ without any options, you can edit
global, per site and per node settings. It is also possible to execute
'modify-config' for a specific node. In this per-node view, it is possible to
set further per-node specific settings like storage plugin settings. Lets
assume you want to use the 'ThinLV' plugin for node 'bravo', where you want to
set the 'pool-name' option to 'mythinpool':

----------------------------
$ drbdmanage modify-config --node bravo
[GLOBAL]
loglevel = INFO

[Node:bravo]
storage-plugin = drbdmanage.storage.lvm_thinlv.LvmThinLv

[Plugin:ThinLV]
pool-name = mythinpool
----------------------------

CAUTION: Currently it is not supported to switch storage plugins on the fly.
The workflow is: Add a new node, modify the configuration for that node, make
use of the node. Changing other settings (like the log-level) is perfectly
fine.

[[s-dm-new-volume]]
=== Creating and deploying resources/volumes
In the following scenario we assume that the goal is to create a resource
'backups' with a size of '500 GB' that is replicated among 3 cluster nodes.
First we show how to achieve the goal in individual steps, and then show a
short-cut how to achieve it in a single step:

First, we create a new resource:

----------------------------
drbdmanage add-resource backups
----------------------------

Second, we create a new volume within that resource:

----------------------------
drbdmanage add-volume backups 500GB
----------------------------
In case we would not have used 'add-resource' in the first step, +drbdmanage+
would have known that the resource did not exist and it would have created it.

The third step is to deploy the resource to 3 cluster nodes:

----------------------------
drbdmanage deploy-resource backups 3
----------------------------

In this case +drbdmanage+ chooses 3 nodes that fit all requirements best,
which is by default the set of nodes with the most free space in the
+drbdpool+ volume group. We will see how to manually assign resources to
specific nodes in a moment.

As deploying a new resource/volume to a set of nodes is a very common task,
+drbdmanage+ provides the following short-cut:
----------------------------
drbdmanage add-volume backups 500GB --deploy 3
----------------------------

Manual deployment can be achieved by *assigning* a resource to specific nodes.
For example if you decide to assign the 'backups' resource to 'bravo' and
'charlie', you should execute the following steps:

----------------------------
drbdmanage add-volume backups 500GB
drbdmanage assign-resource backups bravo
drbdmanage assign-resource backups charlie
----------------------------


[[s-dm-status]]
=== Checking the state of your cluster
+Drbdmanage+ provides various commands to check the state of your cluster.
These commands start with a 'list-' prefix and provide various filtering and
sorting options. The '--groupby' option can be used to group and sort the
output in multiple dimensions. Additional output can be turned on by using the
'--show' option. In the following we show some typical examples:

----------------------------
drbdmanage list-nodes
drbdmanage list-volumes --groupby Size
drbdmanage list-volumes --groupby Size --groupby Minor
drbdmanage list-volumes --groupby Size --show Port
----------------------------

[[s-dm-setupopts]]
=== Setting options for resources
Currently, it is possible to set the following +drbdsetup+ options:

. net-options
. peer-device-options
. disk-options
. resource-options

As for example net-options are allowed in the 'common' section as well as per
resource, these commands then provide the according switches.

Setting +max-buffers+ for a resource 'backups' looks like this:

----------------------------
drbdmanage net-options --max-buffers 2048 --resource backups
----------------------------

Setting this option in the common section looks like this:

----------------------------
drbdmanage net-options --max-buffers 2048 --common
----------------------------

Additionally, there is always an '--unset-' option for every option that can
be specified. So, unsetting +max-buffers+ for a resource 'backups' looks like
this:

----------------------------
drbdmanage net-options --unset-max-buffers --resource backups
----------------------------

It is possible to visualize currently set options with the 'show-options'
subcommand.

Setting +net-options+ per site is also supported. Lets assume 'alpha' and
'bravo' should be part of site 'first' and 'charlie' and 'delta' should be part of
site 'second'. Further, we want to use DRBD protocol 'C' within the two sites, and
protocol 'A' between the sites 'first' and 'second'. This would be set up as follows:

----------------------------
$ drbdmanage modify-config
[Node:alpha]
site = first

[Node:bravo]
site = first

[Node:charlie]
site = second

[Node:delta]
site = second
----------------------------

----------------------------
$ drbdmanage net-options --protocol C --sites 'first:first'
$ drbdmanage net-options --protocol C --sites 'second:second'
$ drbdmanage net-options --protocol A --sites 'first:second'
----------------------------

The '--sites' parameter follows a 'from:to' syntax, where currently 'from' and
'to' have a symetric semantic. Setting an option from 'first:second' also sets this
option from 'second:first'.
