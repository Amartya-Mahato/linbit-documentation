<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="ch-troubleshooting">
  <title>Troubleshooting and error recovery</title>
  <para>
    <para>This chapter describes tasks to be performed in the event of
      hardware or system failures.</para>
  </para>
  <section id="s-hard-drive-failure">
    <title>Dealing with hard drive failure</title>
    <para><indexterm>
	<primary>drive failure</primary>
	<seealso>I/O errors</seealso>
      </indexterm>
      <indexterm>
	<primary>disk failure</primary>
	<seealso>I/O errors</seealso>
      </indexterm>How to deal with hard drive failure depends on the way
      DRBD is configured to handle disk I/O errors (see <xref
    linkend="s-handling-disk-errors"/>), and on the type of meta data
      configured (see <xref linkend="s-metadata"/>).</para>
    <note>
      <para>For the most part, the steps described here apply only if
	you run DRBD directly on top of physical hard drives. They
	generally do not apply in case you are running DRBD layered on
	top of
	<itemizedlist>
	  <listitem>
	    <para>an MD software RAID set (in this case, use
	      <command>mdadm</command> to manage drive replacement),
	    </para>
	  </listitem>
	  <listitem>
	    <para>device-mapper RAID (use <command>dmraid</command>),</para>
	  </listitem>
	  <listitem>
	    <para>a hardware RAID appliance (follow the vendor's
	      instructions on how to deal with failed drives),</para>
	  </listitem>
	  <listitem>
	    <para>some non-standard device-mapper virtual block
	      devices (see the device mapper documentation),</para>
	  </listitem>
	  <listitem>
	    <para><indexterm>
		<primary>EVMS</primary>
	      </indexterm>EVMS volumes (see the EVMS
	      documentation).</para>
	  </listitem>
	</itemizedlist>
      </para>
    </note>
    <section id="s-detach-hard-drive-manual">
      <title>Manually detaching DRBD from your hard drive</title>
       <para><indexterm>
	  <primary>drbdadm</primary>
	  <secondary>detach</secondary>
      </indexterm>If DRBD is <link
	  linkend="fp-io-error-pass-on">configured to pass on I/O
	  errors</link> (not recommended), you must first detach the
	DRBD resource, that is, disassociate it from its backing
	storage:
      <literallayout><userinput>drbdadm detach <replaceable>resource</replaceable></userinput></literallayout>
	By running the <command>drbdadm dstate</command> command, you
	will now be able to verify that the resource is now in
	<indexterm>
	  <primary>diskless mode</primary>
	</indexterm>
	<indexterm>
	  <primary>diskless (disk state)</primary>
	</indexterm>
	<indexterm>
	  <primary>disk state</primary>
	  <secondary>Diskless</secondary>
	</indexterm>
	<emphasis>diskless mode</emphasis>:
	<literallayout><userinput>drbdadm dstate <replaceable>resource</replaceable></userinput>
<computeroutput>Diskless/UpToDate</computeroutput></literallayout>
	If the disk failure has occured on your primary node, you may
      combine this step with a switch-over operation.</para>
    </section>
    <section id="s-detach-hard-drive-auto">
      <title>Automatic detach on I/O error</title>
      <para>If DRBD is <link linkend="fp-io-error-detach">configured
	  to automatically detach upon I/O error</link> (the default,
	and also the recommended option), DRBD should have
	automatically detached the resource from its backing storage
	already, without manual intervention. You may still use the
	<command>drbdadm dstate</command> command to verify that the
	resource is in fact running in diskless mode.</para>
    </section>
    <section id="s-replace-disk-internal-metadata">
      <title>Replacing a failed disk when using internal meta
      data</title>
      <para>If using <link linkend="s-internal-meta-data">internal
	  meta data</link>, it is sufficient to bind the DRBD device
	to the new hard disk. If the new hard disk has to be addressed
	by another Linux device name than the defective disk, this has
	to be modified accordingly in the DRBD configuration
	file.</para>
      <para>This process involves creating a new meta data set, then
      re-attaching the resource:
	<indexterm>
	  <primary>drbdadm</primary>
	  <secondary>create-md</secondary>
	</indexterm>
	<literallayout><userinput>drbdadm create-md <replaceable>resource</replaceable></userinput>
<computeroutput>v08 Magic number not found
Writing meta data...
initialising activity log
NOT initialized bitmap
New drbd meta data block sucessfully created.
success
</computeroutput>
<userinput>drbdadm attach <replaceable>resource</replaceable></userinput></literallayout></para>
      <para>Full synchronization of the new hard disk starts
	instantaneously and automatically. You will be able to monitor
	the synchronization's progress via
	<filename>/proc/drbd</filename>, as with any background
	synchronization.</para>
    </section>
    <section id="s-replace-disk-external-metadata">
      <title>Replacing a failed disk when using external meta
      data</title>
      <para>When using <link linkend="s-external-meta-data">external
	  meta data</link>, the procedure is basically the same.
	However, DRBD is not able to recognize independently that the
	hard drive was swapped, thus an additional step is
	required.
	<literallayout><userinput>drbdadm create-md <replaceable>resource</replaceable></userinput>
<computeroutput>v08 Magic number not found
Writing meta data...
initialising activity log
NOT initialized bitmap
New drbd meta data block sucessfully created.
success
</computeroutput>
<userinput>drbdadm attach <replaceable>resource</replaceable></userinput>
<userinput>drbdadm invalidate <replaceable>resource</replaceable></userinput>
</literallayout></para>
      <para>Here, the <command>drbdadm invalidate</command> command
	triggers synchronization. Again, sync progress may be
	observed via <filename>/proc/drbd</filename>.</para>
    </section>
  </section>
  <section id="s-node-failure">
    <title>Dealing with node failure</title>
    <para><indexterm>
      <primary>node failure</primary>
    </indexterm>
      When DRBD detects that its peer node is down (either by true
      hardware failure or manual intervention), DRBD changes its
      connection state from <code>Connected</code> to
      <code>WFConnection</code> and waits for the peer node to
      re-appear. The DRBD resource is then said to operate in
      <emphasis>disconnected mode</emphasis>. In disconnected mode,
      the resource and its associated block device are fully usable,
      and may be promoted and demoted as necessary, but no block
      modifications are being replicated to the peer node. Instead,
      DRBD stores internal information on which blocks are being
      modified while disconnected.</para>
    <section id="s-temp-node-failure-secondary">
      <title>Dealing with temporary secondary node failure</title>
      <para><indexterm>
	  <primary>node failure</primary>
	  <secondary>temporary</secondary>
      </indexterm>If a node that currently has a resource in the
	secondary role fails temporarily (due to, for example, a
	memory problem that is subsequently rectified by replacing
	RAM), no further intervention is necessary &mdash; besides the
	obvious necessity to repair the failed node and bring it back
	on line. When that happens, the two nodes will simply
	re-establish connectivity upon system start-up. After this,
	DRBD replicates all modifications made on the primary node in
	the meantime, to the secondary node.</para>
      <important>
	<para>At this point, due to the nature of DRBD's
	  re-synchronization algorithm, the resource is briefly
	  inconsistent on the secondary node. During that short time
	  window, the secondary node can not switch to the Primary
	  role if the peer is unavailable. Thus, the period in which
	  your cluster is not redundant consists of the actual
	  secondary node down time, plus the subsequent
	  re-synchronization.</para>
      </important>
    </section>
    <section id="s-temp-node-failure-primary">
      <title>Dealing with temporary primary node failure</title>
      <para><indexterm>
	<primary>node failure</primary>
	<secondary>temporary</secondary>
      </indexterm>
	From DRBD's standpoint, failure of the primary node is
	almost identical to a failure of the secondary node. The
	surviving node detects the peer node's failure, and switches
	to disconnected mode. DRBD does <emphasis>not</emphasis>
	promote the surviving node to the primary role; it is the
	cluster management application's responsibility to do
	so.</para>
      <para>When the failed node is repaired and returns to the
	cluster, it does so in the secondary role, thus, as outlined
	in the previous section, no further manual intervention is
	necessary. Again, DRBD does not change the resource role back,
	it is up to the cluster manager to do so (if so configured).
      </para>
      <para>DRBD ensures block device consistency in case of a primary
	node failure by way of a special mechanism. For a detailed
	discussion, refer to <xref
	  linkend="s-activity-log"/>.</para>
    </section>
    <section id="s-perm-node-failure">
      <title>Dealing with permanent node failure</title>
      <para><indexterm>
	  <primary>node failure</primary>
	  <secondary>permanent</secondary>
	</indexterm>
	If a node suffers an unrecoverable problem or permanent
	destruction, you must follow the following steps:
	<itemizedlist>
	  <listitem>
	    <para>Replace the failed hardware with one with similar
	      performance and disk capacity.<note>
		<para>Replacing a failed node with one with worse
		  performance characteristics is possible, but not
		  recommended. Replacing a failed node with one with
		  less disk capacity is not supported, and will cause
		  DRBD to refuse to connect to the replaced
		  node.</para>
	      </note></para>
	  </listitem>
	  <listitem>
	    <para>Install the base system and applications.</para>
	  </listitem>
	  <listitem>
	    <para>Install DRBD and copy
	      <filename>/etc/drbd.conf</filename> from the surviving
	      node.</para>
	  </listitem>
	  <listitem>
	    <para>Follow the steps outlined in <xref
		linkend="ch-configure"/>, but stop short of
		<xref linkend="s-initial-full-sync"/>. </para>
	  </listitem>
	</itemizedlist>
      </para>
      <para>Manually starting a full device synchronization is not
	necessary at this point, it will commence automatically upon
	connection to the surviving primary node.</para>
    </section>
  </section>
  <section id="s-resolve-split-brain">
    <title>Manual split brain recovery</title>
    <para><indexterm>
	<primary>split brain</primary>
	<secondary>manual recovery</secondary>
      </indexterm>DRBD detects split brain at the time connectivity becomes
      available again and the peer nodes exchange the initial DRBD
      protocol handshake. If DRBD detects that both nodes are (or were
      at some point, while disconnected) in the primary role, it
      immediately tears down the replication connection. The tell-tale
      sign of this is a message like the following appearing in the
      system log:
      <programlisting>Split-Brain detected, dropping connection!</programlisting>
    </para>
    <para>After split brain has been detected, one node will always
      have the resource in a <indexterm>
	<primary>StandAlone (connection state)</primary>
      </indexterm>
      <indexterm>
	<primary>connection state</primary>
	<secondary>StandAlone</secondary>
      </indexterm>
      <code>StandAlone</code> connection state.
      The other might either also be in the <code>StandAlone</code>
      state (if both nodes detected the split brain simultaneously),
      or in 
      <indexterm>
	<primary>WFConnection (connection state)</primary>
      </indexterm>
      <indexterm>
	<primary>connection state</primary>
	<secondary>WFConnection</secondary>
      </indexterm>
      <code>WFConnection</code> (if the peer tore down the
      connection before the other node had a chance to detect split
      brain).</para>
    <para>At this point, unless you configured DRBD to automatically
      recover from split brain, you must manually intervene by
      selecting one node whose modifications will be discarded (this
      node is referred to as the <indexterm>
	<primary>split brain</primary>
	<secondary>victim</secondary>
      </indexterm>
      <emphasis>split brain victim</emphasis>).
      This intervention is made with the following commands:
      <literallayout><userinput>drbdadm secondary <replaceable>resource</replaceable></userinput> 
<userinput>drbdadm -- --discard-my-data connect <replaceable>resource</replaceable></userinput></literallayout> 
      On the other node (the <indexterm>
	<primary>split brain</primary>
	<secondary>survivor</secondary>
      </indexterm>
      <emphasis>split brain survivor</emphasis>), if its connection
      state is also <code>StandAlone</code>, you would enter:
      <literallayout><userinput>drbdadm connect <replaceable>resource</replaceable></userinput></literallayout> 
      You may omit this step if the node is already in the
      <code>WFConnection</code> state; it will then reconnect
      automatically.</para>
    <para>If the resource affected by the split brain is a <link
	linkend="s-three-nodes">stacked resource</link>, use
      <command>drbdadm&nbsp;<option>--stacked</option></command> instead 
      of just <command>drbdadm</command>.</para>
    <para>Upon connection, your split brain victim immediately changes
      its connection state to <code>SyncTarget</code>, and has its
      modifications overwritten by the remaining primary node.
      <note>
	<para>The split brain victim is not subjected to a full device
	  synchronization. Instead, it has its local modifications
	  rolled back, and any modifications made on the split brain
	  survivor propagate to the victim.</para>
      </note>
    </para>
    <para>After re-synchronization has completed, the split brain is
      considered resolved and the two nodes form a fully consistent,
      redundant replicated storage system again.</para>
  </section>
</chapter>
