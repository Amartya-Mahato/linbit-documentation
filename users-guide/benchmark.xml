<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="ch-benchmark" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Measuring block device performance</title>
  <section>
    <title>Measuring throughput</title>
    <para>When measuring the impact of using DRBD on a system's I/O
      throughput, the <emphasis>absolute</emphasis> throughput the
      system is capable of is of little relevance. What is much more
      interesting is the <emphasis>relative</emphasis> impact DRBD has
      on I/O performance. Thus it is always necessary to measure I/O
      throughput both with and without DRBD.
      <caution>
	<para>The tests described in this section are intrusive; they
	  overwrite data and bring DRBD devices out of sync. It is
	  thus vital that you perform them only on scratch volumes
	  which can be discarded after testing has completed.</para>
      </caution>
    </para>
    <para>I/O throughput estimation works by writing significantly
      large chunks of data to a block device, and measuring the amount
      of time the system took to complete the write operation. This
      can be easily done using a fairly ubiquitous utility,
      <code>dd</code>, whose reasonably recent versions include a
      built-in throughput estimation.</para>
    <para>A simple <code>dd</code>-based throughput benchmark,
      assuming you have a scratch resource named <code>test</code>
      which is currently connected and in the secondary role on both
      nodes, is one like the following:
    <programlisting>TEST_RESOURCE=test
TEST_DEVICE=$(drbdadm sh-dev $TEST_RESOURCE)
TEST_LL_DEVICE=$(drbdadm sh-ll-dev $TEST_RESOURCE)
drbdadm primary $TEST_RESOURCE
for i in $(seq 5); do
  dd if=/dev/zero of=$TEST_DEVICE bs=512M count=1
done
drbdadm down $TEST_RESOURCE
for i in $(seq 5); do
  dd if=/dev/zero of=$TEST_LL_DEVICE bs=512M count=1
done</programlisting>
    </para>
    <para>This test simply writes a 512M chunk of data to your DRBD
      device, and then to its backing device for comparison. Both
      tests are repeated 5 times each to allow for some statistical
      averaging. The relevant result is the throughput
      measurements generated by <code>dd</code>.
      <note>
	<para>For freshly enabled DRBD devices, it is normal to see
	  significantly reduced performance on the first
	  <code>dd</code> run. This is due to the Activity Log being
	  <quote>cold</quote>, and is no cause for concern.</para>
      </note>
    </para>
  </section>
  <section>
    <title>Measuring latency</title>
    <para>Latency measurements have objectives completely different
    from throughput benchmarks: in I/O latency tests, one writes a
    very small chunk of data (ideally the smallest chunk of data that
    the system can deal with), and observes the time it takes to
    complete that write. The process is usually repeated several times
    to account for normal statistical fluctuations.</para>
    <para>Just as throughput measurements, I/O latency measurements
      may be performed using the ubiquitous <code>dd</code> utility,
    albeit with different settings and an entirely different focus of
    observation.</para>
    <para>Provided below is a simple <code>dd</code>-based latency
      micro-benchmark, assuming you have a scratch resource named
      <code>test</code> which is currently connected and in the
      secondary role on both nodes:
    <programlisting>TEST_RESOURCE=test
TEST_DEVICE=$(drbdadm sh-dev $TEST_RESOURCE)
TEST_LL_DEVICE=$(drbdadm sh-ll-dev $TEST_RESOURCE)
drbdadm primary $TEST_RESOURCE
dd if=/dev/zero of=$TEST_DEVICE bs=512 count=1000
drbdadm down $TEST_RESOURCE
dd if=/dev/zero of=$TEST_LL_DEVICE bs=512 count=1000</programlisting>
    </para>
    <para>This test writes 1,000 512-byte chunks of data to your DRBD
      device, and then to its backing device for comparison. 512 bytes
      is the smallest block size a Linux system (on all architectures
      except s390) is expected to handle.</para>
    <para>It is important to understand that throughput measurements
      generated by <code>dd</code> are completely irrelevant for this
      test; what is important is the <emphasis>time</emphasis> elapsed
      during the completion of said 1,000 writes. Dividing this time
      by 1,000 gives the average latency of a single sector
      write.</para>
  </section>
</chapter>
